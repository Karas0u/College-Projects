{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building paragraph vectors using Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common text corpus, Doc2Vec algorithm and Tagged Document functionality from Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus on which training will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts\n",
    "#Here's our training corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Tagged Documents from the corpus "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Doc2Vec expects sentences in TaggedDocument format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now convert the tokenized documents into TaggedDocument format and validate this:\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is our corpus in the TaggedDocument form:\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a basic Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's build and train a basic Doc2Vec model \n",
    "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4, epochs = 40)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here, vector size of 5 denotes that each document will be represented by a vector of five floating-point values. The min_count parameter sets a threshold so that only terms that occur at least min_count number of times will be considered in the vocabulary.\n",
    "The workers parameter denotes the number of threads to be used while training to speed up the process. Finally, the epochs parameter represents the number of iterations that will be made over the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the vector size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the vector size for the document embeddings\n",
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many document vectors did we train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SURINDER\\AppData\\Local\\Temp\\ipykernel_17128\\2633262264.py:3: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  len(model.docvecs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check whether the number of document vectors being built is equal to the number of documents \n",
    "#being used in the training process:\n",
    "len(model.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the vocabulary information for the model we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvocab)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "len(model.wv.vocab)\n",
    "#len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.wv.index_to_key\n",
    "model.wv.vocab\n",
    "#Here's our vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's infer a vector based on the trained Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0252012   0.09010135 -0.07160246 -0.04264753  0.08760676]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.042032   -0.02170439  0.06077698  0.03611257 -0.04993226]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer', 'trees'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a new model changing vector size and minimum count eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=3, epochs=40)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvocab)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "len(model.wv.vocab)\n",
    "#len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvocab\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00275315  0.00927881 -0.00654727 -0.00375533  0.00865707  0.0030918\n",
      " -0.00983206  0.00781086 -0.00534719  0.0023765   0.00832855  0.00914602\n",
      "  0.00722278 -0.0080494   0.00907288 -0.00941162 -0.00481918 -0.00206123\n",
      " -0.00371853 -0.00747079  0.00799334  0.0063884  -0.00626846  0.00345137\n",
      "  0.00894975  0.00576471  0.00202684  0.00142986 -0.00124991  0.00473358\n",
      "  0.00555094 -0.00711092 -0.00405471 -0.00299963 -0.00878438 -0.00835046\n",
      " -0.00179125  0.00224573 -0.00236428 -0.00667231  0.00669324  0.00735251\n",
      "  0.00543838  0.001361    0.00751761  0.00958376 -0.00315277  0.00431433\n",
      "  0.00614541 -0.00591232]\n"
     ]
    }
   ],
   "source": [
    "vector1 = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.4323128e-03 -1.0688989e-03  8.0083860e-03  4.7749323e-03\n",
      " -5.6397715e-03 -5.3514340e-03 -4.8345756e-03 -3.1998379e-03\n",
      " -3.6909492e-03 -4.4625914e-03  7.7370653e-04  7.4750911e-03\n",
      "  5.1512723e-03 -4.9892073e-03  3.3175389e-03  9.6221659e-03\n",
      " -5.9786118e-03 -3.5752922e-03 -6.7621320e-03  4.2291293e-03\n",
      "  5.9762462e-03  1.7234727e-03 -8.5616549e-03 -2.6883094e-03\n",
      "  6.2798010e-03  6.8307105e-03 -4.2846720e-03  9.9157430e-03\n",
      "  3.5272821e-04  6.7129666e-03 -2.9019930e-03 -5.7344292e-03\n",
      "  8.7347096e-03 -3.2570078e-03  7.0166835e-03 -8.3021913e-03\n",
      " -1.1807675e-03 -6.5778745e-03  2.4815386e-03 -3.3156641e-04\n",
      "  7.7153952e-03 -5.0899419e-03  3.1003896e-05 -9.2797363e-03\n",
      "  8.9662205e-03  7.0243294e-04  1.7250769e-04  7.1954587e-04\n",
      " -1.3388265e-03 -7.9992237e-03]\n"
     ]
    }
   ],
   "source": [
    "vector2 = model.infer_vector(['user', 'interface', 'for', 'computer', 'trees'])\n",
    "print(vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are two approaches to build paragraph vectors: the PV-DM and PV-DBOW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dm=1 indicates that the model should be based on the distributed memory approach. Here paragraph vectors are concatenated with the word vectors to predict the target word.\n",
    "dm=0 builds the Doc2Vec model based on the distributed bag-of-words approach. Here the paragraph vector gets trained by predicting words in the paragraph itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec based on the distributed memory model (dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00211574  0.00915337 -0.00693545 -0.00377622  0.00843657  0.00327316\n",
      " -0.01007721  0.00827041 -0.00596042  0.00268909  0.00865541  0.0096917\n",
      "  0.00745454 -0.00838413  0.00936548 -0.00994017 -0.00480654 -0.00179974\n",
      " -0.00436808 -0.00758565  0.00761374  0.00643536 -0.00654957  0.00362568\n",
      "  0.00885319  0.00580416  0.00164739  0.00079204 -0.00116876  0.00446676\n",
      "  0.00611638 -0.00664235 -0.0047061  -0.00312531 -0.00881625 -0.00792156\n",
      " -0.00191989  0.00165224 -0.00216513 -0.0067455   0.00625954  0.00778112\n",
      "  0.00525368  0.00075871  0.00718643  0.00992841 -0.0028768   0.0042999\n",
      "  0.00656147 -0.00607138]\n"
     ]
    }
   ],
   "source": [
    "vector1 = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec built next would be based on the distributed bag of words approach (dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.96577951e-04  8.92572477e-03 -7.53967091e-03 -4.11836011e-03\n",
      "  7.97703955e-03  3.69162462e-03 -1.05823399e-02  9.33239609e-03\n",
      " -6.61957497e-03  3.48863285e-03  9.06384178e-03  1.06493644e-02\n",
      "  7.93359801e-03 -8.85376055e-03  1.00990785e-02 -1.06949601e-02\n",
      " -5.47884498e-03 -1.62192597e-03 -5.00717293e-03 -7.37058837e-03\n",
      "  6.98664133e-03  6.48449687e-03 -7.31107127e-03  3.67962942e-03\n",
      "  8.58085137e-03  6.02903264e-03  1.18653907e-03 -3.68781446e-04\n",
      " -1.16685941e-03  4.25128406e-03  7.17442296e-03 -5.65095711e-03\n",
      " -5.95077593e-03 -2.76214327e-03 -9.03856475e-03 -6.83999807e-03\n",
      " -2.41128053e-03  9.68245498e-04 -1.83563703e-03 -6.96342764e-03\n",
      "  5.50191477e-03  8.62030592e-03  4.91271028e-03 -6.57548080e-05\n",
      "  6.12137699e-03  1.07721910e-02 -2.29483400e-03  4.46516369e-03\n",
      "  7.25069223e-03 -6.37954660e-03]\n"
     ]
    }
   ],
   "source": [
    "vector2 = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the window size which controls the maximum distance between current and predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.96577951e-04  8.92572477e-03 -7.53967091e-03 -4.11836011e-03\n",
      "  7.97703955e-03  3.69162462e-03 -1.05823399e-02  9.33239609e-03\n",
      " -6.61957497e-03  3.48863285e-03  9.06384178e-03  1.06493644e-02\n",
      "  7.93359801e-03 -8.85376055e-03  1.00990785e-02 -1.06949601e-02\n",
      " -5.47884498e-03 -1.62192597e-03 -5.00717293e-03 -7.37058837e-03\n",
      "  6.98664133e-03  6.48449687e-03 -7.31107127e-03  3.67962942e-03\n",
      "  8.58085137e-03  6.02903264e-03  1.18653907e-03 -3.68781446e-04\n",
      " -1.16685941e-03  4.25128406e-03  7.17442296e-03 -5.65095711e-03\n",
      " -5.95077593e-03 -2.76214327e-03 -9.03856475e-03 -6.83999807e-03\n",
      " -2.41128053e-03  9.68245498e-04 -1.83563703e-03 -6.96342764e-03\n",
      "  5.50191477e-03  8.62030592e-03  4.91271028e-03 -6.57548080e-05\n",
      "  6.12137699e-03  1.07721910e-02 -2.29483400e-03  4.46516369e-03\n",
      "  7.25069223e-03 -6.37954660e-03]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding initial learning rate and to what value should the learning rate drop to linearly over training (alpha and min_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30997148 -0.05419222 -0.20869155 -0.0094907  -0.12514514  0.12009168\n",
      " -0.17600422  0.1918814  -0.27752745  0.12041155  0.24283369  0.27641186\n",
      "  0.1240024  -0.25481758  0.18184145 -0.3541592  -0.08445887  0.13247225\n",
      " -0.34137362 -0.04781209 -0.0639575   0.0759771  -0.176685    0.16863742\n",
      " -0.03636871  0.00173062 -0.20881394 -0.28400123  0.05654295 -0.1837985\n",
      "  0.33333668  0.2160777  -0.35022303 -0.07953406 -0.09522511  0.1714073\n",
      " -0.02705434 -0.17897056 -0.02569358 -0.01905384 -0.11683214  0.14928779\n",
      "  0.00940733 -0.31112286 -0.06431808  0.1757684   0.18200447 -0.00736232\n",
      "  0.24387175 -0.18112005]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3183066  -0.09446383 -0.2057174   0.03354369 -0.10750768  0.09016126\n",
      " -0.15225726  0.17208654 -0.2296918   0.10481628  0.19542044  0.2910848\n",
      "  0.09422569 -0.18281795  0.14324011 -0.20875874 -0.0382637   0.14597176\n",
      " -0.2458414   0.0191445  -0.14056654  0.05110768 -0.17930299  0.12107011\n",
      "  0.02017868 -0.01917686 -0.19636363 -0.26353478  0.03660677 -0.12466112\n",
      "  0.19426861  0.19536856 -0.28239316 -0.02848074 -0.07285984  0.20085602\n",
      " -0.04884389 -0.16789638 -0.08010467 -0.02761406 -0.13304755  0.07684526\n",
      " -0.08604465 -0.26050475 -0.033079    0.16747399  0.0999692   0.02130131\n",
      "  0.23142117 -0.19943373]\n"
     ]
    }
   ],
   "source": [
    "vector1 = model.infer_vector(['user', 'interface', 'for', 'computer', 'trees'])\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_concat parameter to use concatenation of the word vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dm_concat parameter is used in the PV-DM approach. Its value, when set to 1, indicates to the algorithm that the context vectors should be concatenated while trying to predict the target word. This, of course, leads to building a larger model since multiple word embeddings get concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05, dm_concat=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04736445 -0.19152007 -0.1187445   0.00652415  0.1621975   0.07260685\n",
      "  0.01800431 -0.25172278  0.00330857  0.16784172 -0.09943117 -0.00070348\n",
      " -0.17003772 -0.17329094 -0.00398928 -0.16182724  0.03845131  0.0763863\n",
      " -0.04634567 -0.20069659  0.01315746  0.02568795 -0.09783111  0.03022138\n",
      " -0.22853899 -0.07779045 -0.26734018 -0.01142945  0.0744584  -0.16209894\n",
      "  0.18346117 -0.03536795  0.05940613 -0.20905031  0.08863018 -0.15960747\n",
      "  0.05738065 -0.11140674 -0.00863791  0.0303864   0.21128744 -0.00946644\n",
      "  0.22708647 -0.21699703  0.05482844 -0.06493609  0.04571979 -0.00197637\n",
      "  0.01464513 -0.15476249]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04323404 -0.16983673 -0.07961286  0.07344522  0.1641275   0.02981976\n",
      "  0.02511325 -0.26060644  0.03541024  0.10010695 -0.0991822  -0.02858623\n",
      " -0.18646541 -0.15313089 -0.00816079 -0.13503584  0.05226213  0.0659497\n",
      " -0.01745317 -0.13549705  0.02619831  0.03481792 -0.09810316  0.10668296\n",
      " -0.1635071  -0.08974929 -0.2531391   0.00346655  0.07761529 -0.19694258\n",
      "  0.08558537 -0.06855388  0.10778017 -0.19971116  0.04375234 -0.1629273\n",
      "  0.03714892 -0.09109904 -0.07635406  0.00886129  0.24953265 -0.06930447\n",
      "  0.23476505 -0.15721983  0.1046213  -0.11670952 -0.0183713   0.0476134\n",
      " -0.01371263 -0.16642454]\n"
     ]
    }
   ],
   "source": [
    "vector1 = model.infer_vector(['user', 'interface', 'for', 'computer', 'trees'])\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use sum of the context word vectors (dm_mean=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Instead of concatenating the context vectors, we can sum or average the context vectors. Whether the context vectors should be summed up or averaged can be controlled by the dm_mean parameter. When the dm_mean parameter is set to 1, the mean of the context word vectors is taken. The sum of the context word vectors is taken into account when dm_mean is set to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30997148 -0.05419222 -0.20869155 -0.0094907  -0.12514514  0.12009168\n",
      " -0.17600422  0.1918814  -0.27752745  0.12041155  0.24283369  0.27641186\n",
      "  0.1240024  -0.25481758  0.18184145 -0.3541592  -0.08445887  0.13247225\n",
      " -0.34137362 -0.04781209 -0.0639575   0.0759771  -0.176685    0.16863742\n",
      " -0.03636871  0.00173062 -0.20881394 -0.28400123  0.05654295 -0.1837985\n",
      "  0.33333668  0.2160777  -0.35022303 -0.07953406 -0.09522511  0.1714073\n",
      " -0.02705434 -0.17897056 -0.02569358 -0.01905384 -0.11683214  0.14928779\n",
      "  0.00940733 -0.31112286 -0.06431808  0.1757684   0.18200447 -0.00736232\n",
      "  0.24387175 -0.18112005]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use mean of the context word vectors (dm_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=0, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30997148 -0.05419222 -0.20869155 -0.0094907  -0.12514514  0.12009168\n",
      " -0.17600422  0.1918814  -0.27752745  0.12041155  0.24283369  0.27641186\n",
      "  0.1240024  -0.25481758  0.18184145 -0.3541592  -0.08445887  0.13247225\n",
      " -0.34137362 -0.04781209 -0.0639575   0.0759771  -0.176685    0.16863742\n",
      " -0.03636871  0.00173062 -0.20881394 -0.28400123  0.05654295 -0.1837985\n",
      "  0.33333668  0.2160777  -0.35022303 -0.07953406 -0.09522511  0.1714073\n",
      " -0.02705434 -0.17897056 -0.02569358 -0.01905384 -0.11683214  0.14928779\n",
      "  0.00940733 -0.31112286 -0.06431808  0.1757684   0.18200447 -0.00736232\n",
      "  0.24387175 -0.18112005]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
